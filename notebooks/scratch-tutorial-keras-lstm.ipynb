{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Trains an LSTM model on the IMDB sentiment classification task.\n",
    "The dataset is actually too small for LSTM to be of any advantage\n",
    "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
    "**Notes**\n",
    "- RNNs are tricky. Choice of batch size is important,\n",
    "choice of loss and optimizer is critical, etc.\n",
    "Some configurations won't converge.\n",
    "- LSTM loss decrease patterns during training can be quite different\n",
    "from what you see with CNNs/MLPs/etc.\n",
    "'''\n",
    "from __future__ import print_function\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "maxlen = 80\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa/56062555\n",
    "\n",
    "import numpy as np\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "# call load_data with allow_pickle implicitly set to true\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "# restore np.load for future normal usage\n",
    "np.load = np_load_old\n",
    "\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "WARNING:tensorflow:From /home/yangyq/anaconda3/envs/w266/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/yangyq/anaconda3/envs/w266/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "WARNING:tensorflow:From /home/yangyq/anaconda3/envs/w266/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/15\n",
      "25000/25000 [==============================] - 188s 8ms/step - loss: 0.4560 - acc: 0.7855 - val_loss: 0.4039 - val_acc: 0.8205\n",
      "Epoch 2/15\n",
      "25000/25000 [==============================] - 186s 7ms/step - loss: 0.2983 - acc: 0.8803 - val_loss: 0.3855 - val_acc: 0.8290\n",
      "Epoch 3/15\n",
      "25000/25000 [==============================] - 187s 7ms/step - loss: 0.2176 - acc: 0.9153 - val_loss: 0.4181 - val_acc: 0.8296\n",
      "Epoch 4/15\n",
      "25000/25000 [==============================] - 187s 7ms/step - loss: 0.1519 - acc: 0.9433 - val_loss: 0.4499 - val_acc: 0.8270\n",
      "Epoch 5/15\n",
      "25000/25000 [==============================] - 188s 8ms/step - loss: 0.1117 - acc: 0.9586 - val_loss: 0.5956 - val_acc: 0.8245\n",
      "Epoch 6/15\n",
      "25000/25000 [==============================] - 190s 8ms/step - loss: 0.0770 - acc: 0.9726 - val_loss: 0.6990 - val_acc: 0.8181\n",
      "Epoch 7/15\n",
      "25000/25000 [==============================] - 191s 8ms/step - loss: 0.0590 - acc: 0.9800 - val_loss: 0.7235 - val_acc: 0.8075\n",
      "Epoch 8/15\n",
      "25000/25000 [==============================] - 196s 8ms/step - loss: 0.0456 - acc: 0.9842 - val_loss: 0.7781 - val_acc: 0.8202\n",
      "Epoch 9/15\n",
      "25000/25000 [==============================] - 194s 8ms/step - loss: 0.0362 - acc: 0.9883 - val_loss: 0.9200 - val_acc: 0.8137\n",
      "Epoch 10/15\n",
      "25000/25000 [==============================] - 189s 8ms/step - loss: 0.0239 - acc: 0.9922 - val_loss: 0.8533 - val_acc: 0.8138\n",
      "Epoch 11/15\n",
      "25000/25000 [==============================] - 190s 8ms/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.9508 - val_acc: 0.8173\n",
      "Epoch 12/15\n",
      "25000/25000 [==============================] - 193s 8ms/step - loss: 0.0143 - acc: 0.9958 - val_loss: 1.0182 - val_acc: 0.8099\n",
      "Epoch 13/15\n",
      "25000/25000 [==============================] - 206s 8ms/step - loss: 0.0187 - acc: 0.9941 - val_loss: 0.9623 - val_acc: 0.8094\n",
      "Epoch 14/15\n",
      "25000/25000 [==============================] - 192s 8ms/step - loss: 0.0153 - acc: 0.9952 - val_loss: 1.0260 - val_acc: 0.8136\n",
      "Epoch 15/15\n",
      "25000/25000 [==============================] - 194s 8ms/step - loss: 0.0094 - acc: 0.9972 - val_loss: 1.1199 - val_acc: 0.8085\n",
      "25000/25000 [==============================] - 29s 1ms/step\n",
      "Test score: 1.1199178014814855\n",
      "Test accuracy: 0.80852\n"
     ]
    }
   ],
   "source": [
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
